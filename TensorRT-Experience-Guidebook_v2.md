# TensorRT-Yolov3 Experiment Guidebook

**YOU ONLY LOOK ONCE**

![YOLO](http://image.baidu.com/search/down?tn=download&ipn=dwnl&word=download&ie=utf8&fr=result&url=http%3A%2F%2Fwww.pianshen.com%2Fimages%2F601%2F27ddc806f37e1b5bd193e4d86e3ed779.png&thumburl=http%3A%2F%2Fimg1.imgtn.bdimg.com%2Fit%2Fu%3D3375143915%2C171399236%26fm%3D15%26gp%3D0.jpg "YOLO")

----

This experimental guide mainly describes the application of yolov3 object detection algorithm to track obstacle detection. mainly including label images, train yolov3 model, darknet2caffe, caffemodel2engine.

----

## Requirements
+ Ubuntu 18.04
+ Cuda 10.0
+ Cudnn 7.6.5
+ Python  2.7
+ gcc g++ 5.5.0
+ Caffe
+ Pytorch >= 0.40
+ Opencv 3.4.0
+ TesorRT (same with the tx2 device)

## 1. Label Images

[LabelImg](https://github.com/tzutalin/labelImg "LabelImg") is a graphical image annotation tool. 

### 1.1 Installation
#### Build from source: Ubuntu Linux

Python 2 + Qt4
```
sudo apt-get install pyqt4-dev-tools
sudo pip install lxml
make qt4py2
python labelImg.py
python labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]
```

Python 3 + Qt5 (Recommended)
```
sudo apt-get install pyqt5-dev-tools
sudo pip3 install -r requirements/requirements-linux-python3.txt
make qt5py3
python3 labelImg.py
python3 labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]
```

#### Windows for exe
There is a very simple method, the `LabelImg` provided a exe([here](https://github.com/tzutalin/labelImg/releases "exe")) for windows users.

### 1.2 Hotkeys
| Key | Function |
| --------   | -----:  |
| Ctrl + s | Save |
|w|Create a rect box|
|d|Next image|
|a|Previous image|
|Ctrl++/--|Zoom in or out|

***more details can look the [LabelImg github](https://github.com/tzutalin/labelImg "LabelImg")***

----


## 2.Training Yolo Model
[Yolo official website](https://pjreddie.com/darknet/ "Darknet"), 
[Yolo official github](https://github.com/pjreddie/darknet.git "Darknet")

### 2.1 Installing The Base System
First clone the Darknet git repository here. This can be accomplished by:
```
git clone https://github.com/pjreddie/darknet.git
cd darknet
make
```

If everything seems to have compiled correctly, try running it! Check it ！
```
./darknet
```

You should get the output:
```
usage: ./darknet <function>
```


### 2.2 Training YOLO on Our Datasets

#### Prepare Datasets
Darknet wants a .txt file generated by `LabelImg` for each image with a line for each ground truth object in the image that looks like:
```
<object-class> <x> <y> <width> <height>
```
Next you should generate a train.txt file for each image, which include the each image's path that lools like:
```
/home/hh/darknet/data/pereson/first0.jpg
/home/hh/darknet/data/pereson/first1.jpg
``` 
Finally, putting the each image and its ground truth object txt file into the same file looks like:
```
data/
	person/
		first0.jpg
		first0.txt
		first1.jpg
		first1.txt
```

#### Create Cfg for Data
Now go to your Darknet directory. We have to change the cfg/**voc.data** config file to point to your data:
```
classes= 20
train  = <path-to-data>/train.txt
valid  = <path-to-data>test.txt
names = data/mydata.names
backup = backup
```
rename the voc.data to `mydata.data `

You should replace <path-to-data> with the directory where you put the VOC data.And creating a `mydata.names` file which including the data class id, its looks like:
```
person
bicycle
car 
box
...
```
Next You should change the cfg/yolov3.cfg config file into `cfg/mydata.cfg`, Modification points are as follows:
```
#While training you should comment the code like that:
	## Testing
	#batch=1
	#subdivisions=1

#While testing you should comment the code like that:
	## Training
	#batch=64
	#subdivisions=16

#others modification

width=608  -> 416
height=608 -> 416
steps=400000,450000 ->  <our own steps>

line(610\696\783): classes=80  -> <our datasets classnum>

line(603\689\776): filters=255 -> <our datasets classnum>=(classnum+5)*3
#For example, if the classnun equal 1, the filters is (1+5)*3=18
```

#### Download Pretrained Convolutional Weights

For training we use convolutional weights that are pre-trained on Imagenet. 
We use weights from the darknet53 model. Download the weight and put it in the Darknet directory.
Run the command:
```
cd /home/hh/darknet/
wget https://pjreddie.com/media/files/darknet53.conv.74
```

#### Train The Model
Now we can train! Run the command:
```
./darknet detector train cfg/mydata.data cfg/mydata.cfg darknet53.conv.74
```
If you want to use multiple gpus run:
```
./darknet detector train cfg/mydata.data cfg/mydata.cfg darknet53.conv.74 -gpus 0,1,2,3
```
If you want to stop and restart training from a checkpoint:
```
./darknet detector train cfg/mydata.data cfg/mydata.cfg backup/mydata.backup
```

#### Test The Model

***Caution:*** modify the mydata.cfg to test mode which have been mentioned above.

While U want to test a picture, U should put the trained weights in the darknet/, run the command:
```
./darknet detector test cfg/mydata.data cfg/mydata.cfg mydata.weights data/dog.jpg
```

If U want to test a video file, run the command:
```
./darknet detector demo cfg/mydata.data cfg/mydata.cfg mydata.weights <video file>
```

----


## 3.Converting DarknetModel to CaffeModel

**Code:** [ChenYingpeng/darknet2caffe](https://github.com/ChenYingpeng/darknet2caffe "darknet2caffe")

### 3.1 Requirements

+ Python2.7
+ Caffe
+ Pytorch >= 0.40

### 3.2 Demo 

Needing mydata.cfg and mydata.weights in the darknet2caffe directory.Converting the model:
```
python2 darknet2caffe.py mydata.cfg mydata.weights yolov3.prototxt yolov3.caffemodel
```

### 3.3 Caffe Installation

You can refer to this CSDN blog--`Ubuntu18.04 Caffe 安装步骤记录（超详尽）`, [here](https://blog.csdn.net/yhaolpz/article/details/71375762 "CSDN")

#### Installing dependencies

Running the following commands in order, and making sure the installation is successful.

```
sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler

sudo apt-get install --no-install-recommends libboost-all-dev

sudo apt-get install libopenblas-dev liblapack-dev libatlas-base-dev

sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev

sudo apt-get install git cmake build-essential
```

**Making sure the gcc and g++ version equals 5.5.0**

#### Installing Caffe

##### Clone the caffe source from github:

```
git clone https://github.com/BVLC/caffe.git

cd caffe
sudo cp Makefile.config.example Makefile.config
```

##### Modify Config

Open the Makefile.config by `sudo gedit Makefile.config` and modify it:
Uncomment and apply CUDNN、OPENCV

```
USE_CUDNN := 1 

OPENCV_VERSION := 3

WITH_PYTHON_LAYER := 1
```

Modify the python2 path 
```

INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include

LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib 

After modifying

INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial

LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial  
```

Delete the compute_20 in CUDA_ARCH:
```

CUDA_ARCH := -gencode arch=compute_30,code=sm_30 \

		-gencode arch=compute_35,code=sm_35 \

		-gencode arch=compute_50,code=sm_50 \

		-gencode arch=compute_52,code=sm_52 \

		-gencode arch=compute_60,code=sm_60 \

		-gencode arch=compute_61,code=sm_61 \

		-gencode arch=compute_61,code=compute_61
```

Change `Makefile` in the caffe directory:
```
#change:
NVCCFLAGS +=-ccbin=$(CXX) -Xcompiler-fPIC $(COMMON_FLAGS)
#into 
NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)

#change 
LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_hl hdf5
#into 
LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_serial_hl hdf5_serial 
```

Modify `/usr/local/cuda/include/host_config.h `:
```
change 
#error-- unsupported GNU version! gcc versions later than 4.9 are not supported!

into
//#error-- unsupported GNU version! gcc versions later than 4.9 are not supported!
```

ADD caffe_upsample_layer：
```
caffe_upsample_layer/
	-upsample_layer.hpp  -> include/caffe/layers
	-upsample_layer.cpp  -> src/caffe/layers
	-upsample_layer.cu   -> src/caffe/layers
	-caffe.proto         ->src/caffe/proto/caffe.proto
```

<s>In caffe.proto, add this:
message LayerParameter {
    optional UpsampleParameter upsample_param = 149;
}
At the last line for `LayerParameter`.</s>

##### Compile
In the caffe directory, run:
```
make all -j8
```
After compiling successfully, take a test:
```
make runtest -j8
```

#### Install Pycaffe
Use caffe in python2.7, compile pycaffe firstly.
```
cd caffe 
 
make pycaffe -j8 
```
While the following error occurs , uninstall the all `numpy`, reinstall by `sudo apt-get install python-numpy`
```
python/caffe/_caffe.cpp:10:31: fatal error: numpy/arrayobject.h: 没有那个文件或目录
```
 
If you `import caffe` in python2 ,`ImportError: No module named caffe` error occurs, run this commands:
```
sudo echo export PYTHONPATH="~/caffe/python" >> ~/.bashrc

source ~/.bashrc
```
When `ImportError: No module named skimage.io` error occurs, run `pip install -U scikit-image `.

In this steps, you may `import caffe` in python2 successfully.

----

## 4.Converting CaffeModel to Engine

**Code:** [TensorRT-Yolov3](https://github.com/lewes6369/TensorRT-Yolov3 "TensorRT-Yolov3")

**tensorRT for Yolov3**

### 4.1 Test Environment
+ Ubuntu 18.04 
+ CUDA 10.0 
+ Nvidia-driver-410
+ CUDNN 7.6.5
 
### 4.2 Models Modification

Need: `yolov3.prototxt` and `yolov3.caffemodel` , was generated by `darknet2caffe`.

If run model trained by yourself, comment the "upsample_param" blocks:
```
#delete the line 2622-2624 and 2937-2939
upsample_param{
	scale: 2
}
```
Modify this:
```
input_dim: 1 
input_dim: 3
input_dim: 416 
input_dim: 416 
```
modify the prototxt and add to last layer as:
```
layer {
    #the bottoms are the yolo input layers
    bottom: "layer82-conv"
    bottom: "layer94-conv"
    bottom: "layer106-conv"
    top: "yolo-det"
    name: "yolo-det"
    type: "Yolo"
}
```
**Caution: It also needs to change the yolo configs in "YoloConfigs.h" if different kernels.** 
**We use YOLO 416 and should comment the  YOLO 608 Kernal.**

### 4.3 Run Sample

#### Build Source code 
```
git submodule update --init --recursive
mkdir build
cd build && cmake .. && make && make install
```
OR 
```
git submodule update --init --recursive
mkdir build 
cmake-gui
cd build
make -j6
```

#### CaffeModel2Engine
Put the yolov3.caffemodel and yolov3.prototxt in the TensorRT-Yolov3/build/ directory.
```
#for fp16
./runYolov3 --caffemodel=./yolov3.caffemodel --prototxt=./yolov3.prototxt --input=./test.jpg --W=416 --H=416 --class=<classnum> --mode=fp16

#engine model have exited, use it test our datasets
./runYolov3 --enginefile=yolov3_fp16.engine --input=./test.jpg --W=416 --H=416 --class=<classnum> --mode=fp16
```
**Caution: The version of TensorRT should be consistent with that on tx2, otherwise the engine model is incompatible.**


----
----

## Appendix

### TensorRT

Installation details can refer to the [TensorRT-Installation-Guide.pdf](https://docs.nvidia.com/deeplearning/sdk/tensorrt-install-guide/index.html "pdf")

##### Downloading TensorRT

[TensorRT Download link](https://developer.nvidia.com/nvidia-tensorrt-download "TensorRT")

##### Tar File Installation

Unpack the tar file.
```
tar xzvf TensorRT-5.x.x.x.Ubuntu-1x.04.x.x86_64-gnu.cudax.x.cudnn7.3.tar.gz
```

Add the absolute path to the TensorRT lib directory to the environment variable LD_LIBRARY_PATH:
```
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<eg:TensorRT-5.x.x.x/lib>
```

Install the Python TensorRT wheel file.
```
cd TensorRT-5.x.x.x/python 

#python2 
sudo pip2 install tensorrt-5.x.x.x-py2.py3-none-any.whl 

#python3 
sudo pip3 install tensorrt-5.x.x.x-py2.py3-none-any.whl

```

Install the Python UFF wheel file. This is only required if you plan to use TensorRT
with TensorFlow.
```
cd TensorRT-5.x.x.x/uff
sudo pip install uff-0.5.5-py2.py3-none-any.whl

#test
$ which convert-to-uff
/usr/local/bin/convert-to-uff
```

Install the Python graphsurgeon wheel file.
```
cd TensorRT-5.x.x.x/graphsurgeon

sudo pip install graphsurgeon-0.3.2-py2.py3-none-any.whl
```

##### Verify the installation:

Copy `lenet5.uff` to python dir to verify.
```
sudo cp TensorRT-XXX/data/mnist/lenet5.uff TensorRT-XXX/python/data/mnist/lenet5.uff
cd TensorRT-XXX/samples/sampleMNIST
make clean
make
cd /TensorRT-XXX/bin 
./sample_mnist
```
If the command is executed successfully, the installation is successful.


----



### OpenCV 3.4.0
![OpenCV](https://www.learnopencv.com/wp-content/uploads/2019/11/gaze-tracking-600x394.jpg "opencv") 

**Source code:** [OpenCV 3.4.0](https://opencv.org/releases/page/3/ "CV")

**Installation in Linux:**  [official guidebook](https://docs.opencv.org/3.4.0/d7/d9f/tutorial_linux_install.html
 "book")


----

### Ubuntu18.04+CUDA10.0+CUDNN7.6.5+Nvidia-driver-410

#### 1.Nvidia410 
There are 2 methods to install the nvidia driver:
1.Via Ubuntu `software&update` -> `附加驱动`.
2.Via ppa:

```
#Add Graphic Drivers PPA & Update
sudo add-apt-repository ppa:graphics-drivers/ppa
sudo apt-get update

#Choose the driver version
ubuntu-drivers devices
sudo apt-get install nvidia-driver-410
sudo apt-get install mesa-common-dev
sudo apt-get install freeglut3-dev
```

#### 2.CUDA10.0

##### STEP1:Download the CUDA10.0

Installation package web: [CUDA10.0](https://developer.nvidia.com/cuda-10.0-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=runfilelocal "CUDA")

##### STEP2:Install
In the CUDA package directory, run:
```
sudo sh cuda_10.0.130_410.48_linux.run
```
You can also install its patch: `sudo sh cuda_10.0.130.1_linux.run`

##### STEP3:Configure Environment Variables

```
vim ~/.bashrc
```

Add the following at the end of the bashrc:

```
export PATH=/usr/local/cuda-10.0/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
export CUDA_HOME=/usr/local/cuda
```
Then save and exit.

##### STEP4:Test
Finally, update the source file and check the CUDA:

```
source ~/.bashrc
nvcc --version
cat /usr/local/cuda/version.txt
```
The result:
```
hh@hh-pc:~$ nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130

hh@hh-pc:~$ cat /usr/local/cuda/version.txt 
CUDA Version 10.0.130
```

#### 3.CUDNN7.6.5

Download the [CUDNN](https://developer.nvidia.com/rdp/cudnn-download "cudnn") package.

##### Method 1:
Use the `cudnn-10.0-linux-x64-v7.6.5.32.solitairetheme8`:
###### 1.Extract
```
cp  cudnn-10.0-linux-x64-v7.6.5.32.solitairetheme8 cudnn-10.0-linux-x64-v7.6.5.tgz
tar -xvf cudnn-10.0-linux-x64-v7.6.5.tgz
```

###### 2.Config
```
sudo cp cuda/include/cudnn.h /usr/local/cuda/include/ 
sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/ 
sudo chmod a+r /usr/local/cuda/include/cudnn.h 
sudo chmod a+r /usr/local/cuda/lib64/libcudnn*
```

##### Method 2:
Use the deb:`cuDNN Runtime Library for Ubuntu18.04 (Deb)`,`cuDNN Developer Library for Ubuntu18.04 (Deb)`,`cuDNN Code Samples and User Guide for Ubuntu18.04 (Deb)`

Install this deb files in order:
```
sudo dpkg -i libcudnn7_7.5.0.56-1+cuda10.0_amd64.deb
sudo dpkg -i libcudnn7-dev_7.5.0.56-1+cuda10.0_amd64.deb
sudo dpkg -i libcudnn7-doc_7.5.0.56-1+cuda10.0_amd64.deb

sudo cp /usr/include/cudnn.h /usr/local/cuda/include
sudo chmod a+x /usr/local/cuda/include/cudnn.h
```
##### Test
```
cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
```


----
----


***-------------------------------End---------------------------------***

----






